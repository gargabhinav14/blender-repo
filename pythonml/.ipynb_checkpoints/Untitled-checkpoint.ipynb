{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd9fe58-72c8-418f-976c-84a5434d798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100': 0, '46': 1, '49': 2, '50': 5, '51': 6, '52': 10, '53': 15, '54': 26, '55': 47, '56': 84, '57': 131, '58': 199, '59': 313, '60': 483, '61': 707, '62': 1023, '63': 1494, '64': 2138, '65': 2948, '66': 4019, '67': 5372, '68': 7089, '69': 9171, '70': 11675, '71': 14559, '72': 17937, '73': 21548, '74': 25632, '75': 29761, '76': 34218, '77': 38593, '78': 42814, '79': 46893, '80': 50825, '81': 54184, '82': 57219, '83': 59716, '84': 61845, '85': 63375, '86': 64578, '87': 65445, '88': 66064, '89': 66480, '90': 66759, '91': 66930, '92': 67010, '93': 67044, '94': 67062, '95': 67070, '96': 67075}\n",
      "{0: '100', 1: '46', 2: '49', 5: '50', 6: '51', 10: '52', 15: '53', 26: '54', 47: '55', 84: '56', 131: '57', 199: '58', 313: '59', 483: '60', 707: '61', 1023: '62', 1494: '63', 2138: '64', 2948: '65', 4019: '66', 5372: '67', 7089: '68', 9171: '69', 11675: '70', 14559: '71', 17937: '72', 21548: '73', 25632: '74', 29761: '75', 34218: '76', 38593: '77', 42814: '78', 46893: '79', 50825: '80', 54184: '81', 57219: '82', 59716: '83', 61845: '84', 63375: '85', 64578: '86', 65445: '87', 66064: '88', 66480: '89', 66759: '90', 66930: '91', 67010: '92', 67044: '93', 67062: '94', 67070: '95', 67075: '96'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "   # 2. Create TensorFlow Dataset\n",
    "# def load_and_preprocess_image(image_path, label):\n",
    "#     image = tf.io.read_file(image_path)\n",
    "#     image = tf.image.decode_image(image, channels=3)  # Adjust channels if needed (e.g., grayscale)\n",
    "#     image = tf.image.resize(image, (224, 224))  # Resize images for consistency\n",
    "#     image = tf.keras.applications.resnet50.preprocess_input(image) # Example preprocessing, adjust as needed.\n",
    "#     return image, label\n",
    "\n",
    "def train_image_name_classifier(image_dir, epochs=10, batch_size=32):\n",
    "    \"\"\"\n",
    "    Trains a TensorFlow model to classify images based on their filenames.\n",
    "\n",
    "    Args:\n",
    "        image_dir: The directory containing the images.  Assumes subdirectories\n",
    "                   represent the classes, and image filenames within those\n",
    "                   subdirectories are used as labels.\n",
    "        epochs: The number of training epochs.\n",
    "        batch_size: The batch size for training.\n",
    "\n",
    "    Returns:\n",
    "        A trained TensorFlow model.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Data Preparation\n",
    "\n",
    "    image_paths = []\n",
    "    labels = []  # Store corresponding image name\n",
    "\n",
    "    imageNames = []\n",
    "    # print(os.listdir(image_dir))\n",
    "    for class_name in os.listdir(image_dir):\n",
    "        # class_dir = os.path.join(image_dir, class_name)\n",
    "        # print(os.path.isdir(class_dir))\n",
    "        # if os.path.isdir(class_dir):  # Make sure it's a directory (class folder)\n",
    "        # print(class_name)\n",
    "        # for filename in os.listdir(image_dir):\n",
    "        imageNames.append(class_name)\n",
    "        if class_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')): # Add more extensions if needed\n",
    "            image_path = os.path.join(image_dir, class_name)\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(class_name.split('_')[0]) # Use filename as the label\n",
    "\n",
    "    # print(imageNames)\n",
    "    # print(labels)\n",
    "\n",
    "    # Create a mapping from filename to integer index (important for tf.data)\n",
    "    # unique_labels = sorted(list(set(labels)))  # Ensure consistent order\n",
    "    label_to_index = {label: index for index, label in enumerate(labels)}\n",
    "    index_to_label = {index: label for label, index in label_to_index.items()} # For predictions later\n",
    "\n",
    "    # print(label_to_index)\n",
    "    # print(index_to_label)\n",
    "\n",
    "\n",
    "    numeric_labels = [label_to_index[label] for label in labels] # Convert to numerical labels\n",
    "    print(numeric_labels)\n",
    "\n",
    "    # dataset = tf.data.Dataset.from_tensor_slices((image_paths, numeric_labels)) # Use numeric labels here\n",
    "    # dataset = dataset.map(load_and_preprocess_image).shuffle(len(image_paths)).batch(batch_size)\n",
    "\n",
    "\n",
    "    # # 3. Build the Model\n",
    "\n",
    "    # base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(500,500, 3)) # Or any other model\n",
    "    # base_model.trainable = False  # Freeze the base model initially\n",
    "\n",
    "    # model = tf.keras.Sequential([\n",
    "    #     base_model,\n",
    "    #     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    #     tf.keras.layers.Dense(len(unique_labels), activation='softmax') # Output layer has size equal to number of unique filenames\n",
    "    # ])\n",
    "\n",
    "\n",
    "    # # 4. Compile and Train\n",
    "\n",
    "    # model.compile(optimizer='adam',\n",
    "    #               loss='sparse_categorical_crossentropy', # Use sparse for integer labels\n",
    "    #               metrics=['accuracy'])\n",
    "\n",
    "    # model.fit(dataset, epochs=epochs)\n",
    "\n",
    "\n",
    "    # # 5. Save the Label Mapping (Crucial!)\n",
    "\n",
    "    # import json\n",
    "    # with open('label_mapping.json', 'w') as f:\n",
    "    #     json.dump(index_to_label, f) # Save mapping to JSON file\n",
    "\n",
    "\n",
    "    # return model, index_to_label  # Return the model and mapping\n",
    "\n",
    "# Example usage:\n",
    "image_directory = \"../outputImages\"  # Replace with the actual path\n",
    "train_image_name_classifier(image_directory, epochs=5)\n",
    "# trained_model, label_mapping = train_image_name_classifier(image_directory, epochs=5)  # Adjust epochs as needed\n",
    "\n",
    "# trained_model.save(\"image_name_classifier_model\")  # Save the trained model\n",
    "\n",
    "# # ... (Later, when you want to make predictions) ...\n",
    "\n",
    "# # Load the model and label mapping:\n",
    "# loaded_model = tf.keras.models.load_model(\"image_name_classifier_model\")\n",
    "# with open('label_mapping.json', 'r') as f:\n",
    "#     loaded_label_mapping = json.load(f)\n",
    "\n",
    "# # Example prediction:\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "\n",
    "# def predict_image(image_path):\n",
    "#   img = Image.open(image_path).resize((224, 224))\n",
    "#   img_array = np.array(img)\n",
    "#   img_array = tf.keras.applications.resnet50.preprocess_input(img_array) # Important: Use same preprocessing as training\n",
    "#   img_array = np.expand_dims(img_array, axis=0) # Add batch dimension\n",
    "#   predictions = loaded_model.predict(img_array)\n",
    "#   predicted_index = np.argmax(predictions)\n",
    "#   predicted_label = loaded_label_mapping[str(predicted_index)] # Look up label using index\n",
    "#   return predicted_label\n",
    "\n",
    "# predicted_name = predict_image(\"path/to/new/image.jpg\")\n",
    "# print(f\"Predicted image name: {predicted_name}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223bfe5-c628-4f3f-8519-1833968efad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
